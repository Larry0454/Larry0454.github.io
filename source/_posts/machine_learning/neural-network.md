---
title: 『machine learning-7』neural network
date: 2024-03-28 08:29:00
tags: machine learning
---

## 神经网络

---

###  一、感知器

- 感知器的定义：以一个**实值向量**为输入，计算输入中**各分量的线性组合**，最后通过**激活函数**计算输出

  感知器的输出计算公式：
  $$
  o(x_1, ..., x_n) = 
  \begin{cases}
  1 & \omega_0 + \omega_1 x_1 + ... + \omega_n x_n \gt 0 \\
  -1 & otherwise
  \end{cases}
  $$
  上式中激活函数取符号函数$sgn(x)$

  **注意**：一般会设置一个**固定的输入$x_0 = 1$**，则上面的不等式可写成 $\sum_{i=0}^n \omega_i x_i \gt 0$

  ---

- 感知器的表征能力：可解决**线性可分问题**

  - 线性可分：设样例是n维实例空间中的点

    若存在<u>一个超平面决策面</u>正好可以**将正反样例划分开**，说明被划分的集合称为线性可分集合

    超平面方程即为 $\vec{\omega} \cdot \vec{x} = 0$

  - m-of-n 问题：设1为布尔真、0为布尔假；要使得感知器输出为真，则感知器的<u>n个输入中至少需有m个输入为真</u>

    设置所有的 $\omega_i$ = 0.5（$i \ge$ 1），再设置适当的阈值（$\omega_0$）即可；如“或门”的$\omega_0 \gt -0.5$

    **注意**：“与或非”都是常见的线性可分运算，“异或”不是（不能用单一的感知器计算）

  ---

- 感知器的训练法则：从随机的一组权值开始，将所有训练样例提交给感知器

  只要出现误分类就修改权值，直至感知器**正确分类所有样例**，设输入样例$(x_i, t)$对应的权值为$\omega_i$：
  $$
  \begin{align}
  \omega_i &\leftarrow \omega_i + \Delta \omega_i \\
  其中权重增量 \Delta \omega_i &= \eta (t - o)x_i
  \end{align}
  $$
  其中o表示感知器的当前输出，$\eta \in (0, 1)$表示**学习速率**

  由训练法则可知，若<u>当前输出</u>与<u>样例属性值</u>相等，对应权值就不会调整

  ---

- 梯度下降和delta法则：

  - 感知器训练法则：仅能对线性可分的样本做分类

  - delta法则：通过**梯度下降**求出非线性可分计算的最佳近似（<u>学习率 * 输入值 * 输出误差</u>）

  - 梯度下降：搜索使**误差最小化**的权值向量，设线性单元输出$o(\vec{x}) = \vec{\omega} \cdot \vec{x}$

    - 训练误差：$E(\vec{\omega}) = \frac{1}{2} \sum_{d \in D} (t_d - o_d)^2$

      其中D是样本集，$t_d$是样本属性值，$o_d$是当前线性单元的输出

    - 梯度：函数E上升**最陡峭**的方向，$\nabla E = (\frac{\partial E}{\partial \omega_0}, ...,\frac{\partial E}{\partial \omega_n})$，故设调整方向 $\Delta \vec{\omega} = -\eta \nabla E(\vec{\omega})$

    - 梯度下降算法：初始化$\Delta \omega_i = 0$，对训练样本中的所有样本$(\vec{x}, t)$，<u>累计</u>计算所有的**权值增量**：
      $$
      \Delta \omega_i \leftarrow \Delta \omega_i + \eta (t - o) x_i
      $$
      最后**调整各权值分量**：
      $$
      \omega_i \leftarrow \omega_i + \Delta \omega_i
      $$
      **注意**：学习速率$\eta$必须**足够小**，以防止步幅过大跨过最小误差对应的权值向量

  - 随机梯度下降：解决<u>收敛速度过慢</u>或<u>陷入局部极小</u>的问题

    - 标准梯度下降：在权值更新之前**先汇总**所有样例的误差
      $$
      \Delta \omega_i = \eta \sum_{d \in D} (t_d - o_d)x_{di}
      $$
      <u>随机梯度下降</u>：根据每个样例$(\vec{x}, t)$**直接更新**各权值
      $$
      \Delta \omega_i = \eta (t - o) x_i
      $$
  
  **注意**：感知器训练法则是根据**阈值输出**调整权值，而delta法则是直接根据**线性单元输出**调整权值

---

### 二、多层网络和反向传播算法 ⭐

- 多层网络：具有**隐藏层**，能够表示<u>高度非线性</u>的决策面（如曲面）

- 可微阈值单元：适用于梯度下降算法**非线性**的**可微**函数

  sigmoid函数：常见的平滑可微的阈值函数
  $$
  sigmoid(x) = \frac{1}{1 + e^{-x}}
  $$

- sigmoid函数的特殊性质：记sigmoid为$\sigma$，有$\sigma' = \sigma(1-\sigma)$

  ---

- 反向传播算法（BP算法）：通过**梯度下降**最小化<u>网络输出值</u>和<u>目标值之间</u>的误差平方

  设$x_{ji}$为神经元j的第i个**输入**，$\omega_{ji}$表示对应的**权重**，$net_j$表示神经元j**输入的线性加权**，$o_j$表示神经元j的**阈值输出**

  downstream(j)表示以神经元j的输出为直接输入的**下一层神经元**的集合

  <figure style="text-align:center;">
    <img src = "BP算法.png" width=80% height=80%>
    <figcaption>BP算法图示</figcaption>
  </figure>
  对于训练样本集中的每个样例$(\vec{x_i}, t)$，将其输入网络，使误差沿网络反向传播：
  
  1. 对于网络中的每个**输出神经元k**，计算其误差项$\delta_k = o_k(1-o_k)(t_k - o_k)$ （$\sigma' \Delta out）$
  
  2. 对于网络中的每个**隐层神经元h**，计算其误差项$\delta_h = o_h(1-o_h) \sum_{k \in downstream(h)} \delta_k \omega_{kh}$（<u>**向前递推**</u>）
  
     第m层神经元的误差项是由**所有第m+1层神经元**的误差项推导出来的
  
  3. **更新**各网络权值$\omega_{ji} \leftarrow \omega_{ji} + \Delta \omega_{ji}$，其中$\Delta \omega_{ji} = \eta \delta_{j} x_{ji}$
  
  反向传播算法的终止条件：固定的迭代次数（一轮<u>迭代</u>指<u>读取一遍训练集</u>），或误差降至某个阈值以下

​				**注意**：上面的BP算法适用于任何“无环”网络学习，downstream也不要求各层网络中的神经元整齐排列在一行内

- BP算法的推导思路：设样本d的误差平方$E_d(\vec{\omega}) = \frac{1}{2} \sum_{k \in outputs} (t_k - o_k)^2$

  由梯度下降算法，对每个训练样例d，需要求解 $\Delta \omega_{ji} = -\eta \frac{\partial E_d}{\partial \omega_{ji}}$，即调整梯度的增量

  神经元j的输入权值$\omega_{ji}$<u>仅通过加权和$net_j$</u>影响**后方的网络**，由链式法则：
  $$
  \begin{align}
  \frac{\partial E_d}{\partial \omega_{ji}} &= \frac{\partial E_d}{\partial net_j} \frac{\partial net_j}{\partial \omega_{ji}} \\
  &= \frac{\partial E_d}{\partial net_j} x_{ji} = -\delta_j x_{ji}
  \end{align}
  $$
  若神经元j是**输出神经元**：神经元j的加权和$net_j$<u>仅通过输出$o_j$</u>影响**后方的网络**
  $$
  \begin{align}
  \frac{\partial E_d}{\partial net_j} &= \frac{\partial E_d}{\partial o_j} \frac{\partial o_j}{\partial net_j} \\
  &= \frac{\partial}{\partial o_j}[\frac{1}{2} (t_j - o_j)^2] \frac{\partial \sigma(net_j)}{\partial net_j} \\
  &= -(t_j - o_j)o_j(1-o_j)
  \end{align}
  $$
  若神经元j是**隐层神经元**：神经元j的加权和$net_j$<u>通过其**所有**下游神经元</u>影响**后方的网络**
  $$
  \begin{align}
  \frac{\partial E_d}{\partial net_j} &= \sum_{k \in downstream(j)} \frac{\partial E_d}{\partial net_k} \frac{\partial net_k}{\partial net_j} \\
  &= \sum_{k \in downstream(j)} -\delta_k (\frac{\partial net_k}{\partial o_j} \frac{\partial o_j}{\partial net_j}) \\
  &= \sum_{k \in downstream(j)} -\delta_k \omega_{kj} o_j(1-o_j) \\
  &= -\delta_j
  \end{align}
  $$

  ---

- 收敛性与局部极小值

  - 基于迭代的反向传播算法可能导致误差E收敛到某个**局部极小值**

  - 如何缓解局部极小值问题：“启发式规则”

    - 为梯度增量增设一个**冲量项**：$\Delta \omega_{ji}(n) = \eta \delta_jx_{ji} + \alpha \Delta \omega_{ji}(n - 1)$

      其中增加的第二项就是冲量项，冲量常数 $0 \le \alpha \lt 1$；n表示第n轮迭代

      冲量项有可能助力网络跳出局部极小值

    - 以**多组不同初始权重**训练神经网络，取其中误差E最小的参数训练结果作为最终参数（相当于从<u>多个初始点</u>开始搜索）

    - 使用“模拟退火”技术：模拟退火的每一步迭代都以**一定概率**接受比当前解更差的结果，从而有概率跳出局部极小值

  ---

- 前馈网络的表征能力：

  - 布尔函数：任何布尔函数都可由**两层网络**准确表示

    对<u>每种可能的输入向量</u>，创建不同的隐藏神经元，设置其权值使得**仅当对应的向量输入才能激活它**

    再将输出单元设置为一个**仅可由期待的输入向量**激活的**或门**

  - 连续函数：每个有界的连续函数可由**两层网络**以<u>任意小的误差</u>逼近；隐藏层使用sigmoid函数，输出层使用（非阈值）线性单元

  - 任意函数：任意函数可被**三层网络**以<u>任意精度</u>逼近；两个隐藏层使用sigmoid函数，输出层使用（非阈值）线性单元
  

---

### 三、关于神经网络的拓展讨论

- 误差函数的选取：除了误差平方和函数E，还有其它目标函数可供选择

  - 为权值增加一个**惩罚项**：通过<u>权重的平方和</u>考察网络的**复杂程度**，减小**过拟合**的风险，$\gamma \in (0, 1)$
    $$
    E(\vec{\omega}) = \frac{1}{2} \sum_{d \in D} \sum_{k \in outputs} (t_{kd} - o_{kd})^2 + \gamma \sum_{i, j} \omega_{ji}^2
    $$

  - 对误差增加一项**目标函数的斜率或导数**：考察<u>训练导数</u>和<u>网络的实际导数</u>间的差异
    $$
    E(\vec{\omega}) = \frac{1}{2} \sum_{d \in D} \sum_{k \in outputs} [(t_{kd} - o_{kd})^2 + \mu \sum_{j \in inputs}(\frac{\partial t_{kd}}{\partial x_d^j} - \frac{\partial o_{kd}}{\partial x_d^j})^2]
    $$
    其中$x_d^j$表示训练实例d的第j个输入单元的值

  - 设置目标值为**交叉熵**：将**离散的分类输出**转化为**连续的概率输出**，交叉熵定义：
    $$
    -\sum_{d \in D} t_d\log o_d + (1 - t_d)\log(1 - o_d)
    $$
    其中$o_d$表示对样例d输出的**概率估计**，$t_d$表示训练样例的**目标值**

  ---

- 其它常见神经网络：

  - RBF网络：单隐层前馈神经网络

    其激活函数：径向基函数，表示样本到数据中心的欧氏距离
    $$
    \rho(x, c_i) = e^{-\beta_i |{|{x - c_i}}|| ^2}
    $$
    输出层是隐层神经元输出的线性组合：其中q表示q个输出神经元
    $$
    \Phi(x) = \sum_{i=1}^q \omega_i \rho(x, c_i)
    $$
  
    ---
  
  - ART网络：自适应谐振理论网络，**竞争型学习**的代表

    - 网络组成：比较层、识别层、**识别阈值**、重置模块

      - 比较层：**接收**输入样本，并将其**传递**给识别层神经元

      - 识别层：该层的各神经元都拥有其对应模式的**代表向量**，与输入向量距离最近的神经元**获胜**，并抑制其它神经元的激活

        - 输入向量和获胜单元间距**大于识别阈值**：该输入样本被**归为**代表向量所属类，并**更新连接权**，使得下次接收到<u>类似向量</u>后会计算出**更大的相似度**
        - 输入向量和获胜单元间距**不大于识别阈值**：重置模块在识别层设置**新的神经元**，<u>其代表向量即为当前输入向量</u>
  
        **注意**：如果识别阈值较高，就会划分出**更多更精细**的代表向量
  
    - “可塑性”和“稳定性”：
  
      - “可塑性”指神经网络要拥有<u>学习新知识</u>的能力

      - “稳定性”指神经网络在学习新知识的<u>同时要保持对旧知识的记忆</u>
  
    ---
  
  - SOM网络：自组织映射网络，竞争型学习的代表
  
    - 特点：可将高维输入映射到低维（如二维）空间
  
      同时保证高维空间中<u>相似的样本点</u>映射到输出层中的<u>邻近神经元</u>

    - 输出层神经元：每个神经元都有一个**权向量**，<u>与输入向量间距最近</u>的神经元称为**最佳匹配单元**
  
      最佳单元邻近的权向量会被调整，使其**周围权向量与输入向量的间距缩小**
  
    ---
  
  - 级联相关网络：结构自适应网络的重要代表
  
    - 特点：在训练过程中寻找最符合数据特点的**网络结构**
  
    - 级联：网络层次连接的层次结构，在训练的过程中可能会有**新的隐层神经元加入**
  
    - 相关：**最大化**<u>新神经元的输出</u>与<u>网络误差</u>间的相关性
  
      **注意**：新神经元的<u>输入端权值是固定的</u>，其输出端权重是训练可变的对象
  
    ---
  
  - Elman网络：递归神经网络的代表
  
    - 递归神经网络：包含**有向环**结构，神经元的输出可反馈作为输入信号，可处理**时序相关**的变化
  
      <figure style="text-align:center;">
        <img src = "Elman网络.png" width=30%>
        <figcaption>Elman递归网络结构</figcaption>
      </figure>
  
    ---
  
  - Boltzmann机：基于能量的模型
  
    - 结构：由布尔型神经元组成（抑制“0”或激活“1”）；包含“显层”和“隐层”神经元，两层神经元间形成<u>全连接</u>
    
    - 状态向量$\vec{s}$：$\vec{s} \in \{0, 1\}^n$ 表示n个神经元的状态
    
    - Boltzmann机能量：设$\omega_{ij}$表示神经元i和j之间权连接，$\theta_i$表示神经元i的阈值，n神经元能量：
      $$
      E(\vec{s}) = -\sum_{i=1}^{n-1} \sum_{j=i+1}^n \omega_{ij} s_i s_j - \sum_{i=1}^n \theta_i s_i
      $$
      即<u>总能量 = 边权能量 + 节点能量</u>
    
      状态向量$\vec{s}$**出现的概率**仅有其能量和所有可能的状态向量的能量决定：
      $$
      P(\vec{s}) = \frac{e^{-E(\vec{s})}}{\sum_{\vec{t}}e^{-E(\vec{t})}}
      $$
    
    - 训练过程：将每个<u>样本</u>视为一个<u>状态向量</u>，**最大化其出现的概率**
    
    - CD算法：设网络中有d个<u>显层</u>神经元和q个<u>隐层</u>神经元
    
      令$\vec{v}$和$\vec{h}$分别表示显层与隐层的**状态向量**，现根据样本$\vec{v}$计算隐层概率分布：
      $$
      P(\vec{h}|\vec{v}) = \Pi_{i=1}^q P(h_i | \vec{v})
      $$
      再根据上述概率分布**采样**得到隐层向量$\vec{h}$，并**计算**显层概率分布：
      $$
      P(\vec{v}|\vec{h}) = \Pi_{i=1}^d P(v_i | \vec{h})
      $$
      由上述概率分布**采样**得到$\vec{v}'$，类似地由$\vec{v}'$**计算**获得$\vec{h}'$，最后**更新连接权重**：
      $$
      \Delta \omega = \eta (\vec{v} \vec{h}^T - \vec{v}' \vec{h}'^T)
      $$

---

- 深度学习：一般指**很深层**的神经网络

  - 无监督逐层训练：“预训练 + 微调”：

    - 预训练：每次训练**一层**隐节点：
      1. 将上一层隐节点的输出作为输入
      2. 将本层隐节点的输出作为下一层隐节点的输入
    - 微调：预训练全部完成后，对整个网络进行微调（如BP算法）

    这种训练方式实际上是从各层**局部最优**出发寻找**全局最优**

    ---

  - “权共享”策略：让一组神经元共享<u>相同的连接权</u>，在**卷积神经网络**中应用较多

    - 卷积层：包含多个**特征映射**，即神经元组成的平面

    - 特征映射：其中的<u>每个神经元</u>负责从**输入的部分区域**内通过卷积滤波器**提取特征**

    - 采样层：其中的<u>每个神经元</u>负责从**特征映射层的部分区域**计算输出，起到**精简数据量**的作用

      通过复合卷积层 + 采样层，最终实现了将<u>高维信息</u>映射到<u>低维数据</u>的xiao'guo

    **注意**：层数越多，特征越全局
    
  - 池化：对不同位置的特征值进行聚合统计（max or min or random），达到降维 + 防止过拟合的效果
  
  - 梯度消失：随着隐藏层数量的增加，不同层之间的梯度开始消失，下面是常见的解决方案：
  
    - 线性整流激活函数：ReLU(x) = max(0, x)
    - 归一化：对激活后的输出进行归一化
    - 残差网络：在输入和输出之间添加跳跃连结，允许梯度直接流过





